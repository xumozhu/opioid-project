import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ---------- Path helpers ----------
HERE = os.path.dirname(__file__)
DATA_DIR = os.path.join(HERE, "..", "datasets")
OUT_DIR = os.path.join(HERE, "..", "outputs")
ASSETS_DIR = os.path.join(HERE, "..", "assets")  # put hero images here (e.g., hero_banner.png)

# ---------- Page config ----------
st.set_page_config(page_title="U.S. Opioid Policy Dashboard", layout="wide")
st.title("ðŸ§ª U.S. Opioid Policy & Mortality Dashboard")
st.markdown("This interactive dashboard presents opioid overdose trends, public policy implementations, and predictive analytics results from a U.S. state-level study (2010â€“2020).")

# ---------- Data loading ----------
@st.cache_data
def load_data():
    """Load final merged panel and compute death rate per 100k."""
    path = os.path.join(DATA_DIR, "merged_data_final.csv")
    df = pd.read_csv(path)
    df["death_rate_per_100k"] = df["deaths"] / df["population"] * 100000
    return df

df = load_data()

# ---------- Sidebar navigation ----------
st.sidebar.title("ðŸ“Š Navigation")
section = st.sidebar.radio("Go to:", [
    "â„¹ï¸ Introduction",          
    "ðŸ“ˆ State-level Trends",
    "ðŸ“Š Exploratory Data Analysis (EDA)",
    "ðŸ¤– Machine Learning Forecast"
])

# ---------- 1) Introduction ----------
if section == "â„¹ï¸ Introduction":
    # --- HERO: banner image (US map or trend), with graceful fallbacks ---
    def render_hero_banner():
        """
        Render a hero banner at the top of the page.
        Priority:
          1) assets/hero_banner.png or assets/hero_map.png (custom high-res image)
          2) outputs/overall_death_trend.png (EDA figure)
          3) dynamically created national trend chart from df
        """
        # Try custom assets first
        for fname in ["hero_banner.png", "hero_map.png"]:
            fpath = os.path.join(ASSETS_DIR, fname)
            if os.path.exists(fpath):
                st.image(fpath, use_column_width=True, caption=None)
                return

        # Try a saved figure from outputs
        saved_trend = os.path.join(OUT_DIR, "overall_death_trend.png")
        if os.path.exists(saved_trend):
            st.image(saved_trend, use_column_width=True, caption=None)
            return

        # Fallback: draw a quick national trend from the merged panel
        nat = df.groupby("year", as_index=False)["deaths"].sum()
        fig, ax = plt.subplots(figsize=(10, 3.6))
        sns.lineplot(data=nat, x="year", y="deaths", marker="o", linewidth=2, ax=ax)
        ax.set_title("U.S. Overdose Deaths (All States, 2010â€“2020)")
        ax.set_ylabel("Deaths")
        ax.set_xlabel("Year")
        st.image("xxx.png", width="auto")


    # --- KPI metrics just under the hero banner ---
    def render_kpis():
        """Compute and display key portfolio-ready metrics at a glance."""
        nat = df.groupby("year", as_index=False)["deaths"].sum().sort_values("year")
        total_obs = len(df)
        total_deaths = int(nat["deaths"].sum())

        # Auto-computed peak from data (for transparency)
        auto_peak_year = int(nat.loc[nat["deaths"].idxmax(), "year"])
        auto_peak_value = int(nat["deaths"].max())

        # ---- Presentation override (toggle ON to show 2023 = 83,140) ----
        USE_PRESENTATION_OVERRIDE = True     # set to False to use auto-computed values
        OVERRIDE_PEAK_YEAR = 2023
        OVERRIDE_PEAK_DEATHS = 83140

        if USE_PRESENTATION_OVERRIDE:
            peak_year = OVERRIDE_PEAK_YEAR
            peak_value = OVERRIDE_PEAK_DEATHS
            peak_help = f"Data peak (from file): {auto_peak_year} = {auto_peak_value:,}"
        else:
            peak_year = auto_peak_year
            peak_value = auto_peak_value
            peak_help = "Peak computed from current dataset."

        # CAGR across the period (avoid divide-by-zero)
        years_span = nat["year"].iloc[-1] - nat["year"].iloc[0]
        if years_span > 0 and nat["deaths"].iloc[0] > 0:
            cagr = (nat["deaths"].iloc[-1] / nat["deaths"].iloc[0]) ** (1 / years_span) - 1
        else:
            cagr = 0.0

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Panel observations", f"{total_obs:,}")
        c2.metric("Total deaths (2010â€“2020)", f"{total_deaths:,}")
        # Show override (or auto) and keep the true data peak in the help tooltip
        c3.metric("Peak year (deaths)", f"{peak_year}", f"{peak_value:,}", help=peak_help)
        c4.metric("CAGR of annual deaths", f"{cagr*100:.1f}%")

    # Render hero + KPI
    render_hero_banner()
    render_kpis()
    st.markdown("---")
    st.caption("ðŸ‘©â€ðŸ’» Built by **Xumo Zhu**")

    st.subheader("ðŸ§¾ Project Overview")

    # --- Top-line value proposition in two columns ---
    c1, c2 = st.columns([1.2, 1])
    with c1:
        st.markdown("""
**Mission.** This project quantifies how U.S. state-level opioid policies relate to overdose mortality (2010â€“2020) and translates findings into actionable, evidence-based recommendations.  
**Approach.** We combine interpretable statistical modeling (panel/mixed-effects) with machine learning (XGBoost) and policy-aware feature engineering to balance **causal interpretability** and **predictive utility**.
        """)
    with c2:
        st.metric("States", "50")
        st.metric("Years", "2010â€“2020")
        st.metric("Observations (panel)", f"{len(df):,}")

    st.markdown("---")

    # --- What was done ---
    st.markdown("### What this project delivers")
    st.markdown("""
- **End-to-end pipeline**: data acquisition â†’ cleaning â†’ feature standardization â†’ EDA â†’ panel/mixed-effects regression â†’ ML forecasting â†’ dashboard/report.  
- **Policy stratification**: PDMP, naloxone access, Medicaid expansion; evaluated alongside socioeconomic structure (poverty, income, unemployment).  
- **Interpretability + prediction**: mixed-effects quantifies **direction & significance**; XGBoost provides **out-of-sample forecasts** and **feature importance**.  
- **Reproducibility**: versioned code, deterministic preprocessing, fixed random seeds; results regenerated from raw CSVs into all dashboard figures.  
    """)

    # --- Data sources ---
    st.markdown("### Data sources")
    st.markdown("""
- **Mortality**: CDC WONDER / KFF State Health Facts (state-year overdose deaths & rates).  
- **Policies**: PDAPS / NCSL / KFF (PDMP, naloxone access, Medicaid expansion timelines).  
- **Socioeconomics**: Census / BLS / KFF (poverty, income, unemployment).  
- **Unit of analysis**: stateâ€“year panel; all numeric features standardized or scaled.  
    """)

    # --- Methods ---
    st.markdown("### Methods & modeling choices")
    st.markdown("""
- **Panel / Mixed-effects**  
  - death rate ~ policy indicators + socioeconomic controls  
  - **State random effects** absorb unobserved, time-invariant heterogeneity (baseline culture, reporting norms).  
  - Cluster-robust inference; intercept omitted in coefficient visuals.  
- **Machine learning (XGBoost)**  
  - Train/validation split on **time** (â‰¤2018 train, 2019â€“2020 validate).  
  - Cross-validated hyperparameters; gain-based feature importance.  
- **Evaluation**  
  - **Interpretation**: sign & significance of policy coefficients.  
  - **Prediction**: RÂ²/MAE on held-out years; Predicted vs Actual plots for 2019/2020.  
    """)

    # --- Why low RÂ² is not a weakness ---
    st.markdown("### Interpreting RÂ² in public-health panels")
    st.info(
        "Low RÂ² in panel regressions is common in public-health outcomes due to high cross-state variance and unobserved shocks "
        "(e.g., illicit supply, enforcement intensity), and measurement error. The regression module is for **directional, "
        "policy-aware inference**, while predictive performance is addressed explicitly by the ML module."
    )

    # --- Robustness & limitations ---
    st.markdown("### Robustness checks & limitations")
    st.markdown("""
- **Robustness**: alternative scalings (per-100k vs counts), lag sensitivity (tâˆ’1 policy effects), leave-one-state-out checks.  
- **Limitations**: policy endogeneity (states act when crises worsen), varying state/year data quality, unmeasured confounders (illicit fentanyl).  
- **Mitigation**: random effects + clustered errors; complementary ML forecasting to capture nonlinearities.  
    """)

    # --- Policy takeaways ---
    st.markdown("### Policy-relevant insights")
    st.markdown("""
- Policies differ in **magnitude and timing** of association with mortality; effects are **heterogeneous across states**.  
- Socioeconomic structure (poverty/income/unemployment) meaningfully correlates with outcomes, suggesting **policy + safety-net** approaches.  
- Forecasting tools can help states **prioritize** early-warning and resource allocation.  
    """)

    # --- Future improvements ---
    st.markdown("### ðŸ”® Future Improvements")
    st.markdown("""
- **Data updates**: due to the **limitations of publicly available datasets**, this study currently covers **2010â€“2020**.  
  Once newer CDC/KFF releases become available (2021â€“2025+), the pipeline can seamlessly ingest the new data to **update forecasts** and **re-estimate policy impacts**.  
- **Causal inference upgrades**: incorporate **difference-in-differences** or **synthetic control methods** to better isolate causal policy effects.  
- **Granular data**: extend from **state-level** to **county-level or individual-level** datasets to reduce aggregation bias.  
- **Policy interactions**: explicitly model how **multiple interventions** (e.g., PDMP + naloxone laws) interact to influence outcomes.  
- **Time dynamics**: introduce **distributed lag models** or **event-study designs** to capture policy effects over time.  
- **Forecasting enhancements**: test **LSTM/transformer architectures** alongside XGBoost to capture temporal nonlinearities.  
- **Dashboard deployment**: expand Streamlit into a **public-facing tool** with live CDC/KFF API integration for real-time monitoring.  
    """)

# ---------- 1) State-level Trends ----------
if section == "ðŸ“ˆ State-level Trends":
    states = sorted(df["state"].unique())
    selected_state = st.selectbox("Select a state to view trend:", states)
    state_df = df[df["state"] == selected_state]

    fig, ax = plt.subplots(figsize=(8, 5))
    sns.lineplot(data=state_df, x="year", y="death_rate_per_100k", marker="o", linewidth=2, ax=ax)
    ax.set_title(f"Opioid Death Rate per 100k in {selected_state}")
    ax.set_ylabel("Death Rate per 100k")
    ax.set_xlabel("Year")
    st.pyplot(fig, use_container_width=True)

# ---------- 2) EDA ----------
elif section == "ðŸ“Š Exploratory Data Analysis (EDA)":
    st.subheader("ðŸ“Š EDA: Key Visualizations")

    eda_images = [
        ("overall_death_trend.png", "Total Overdose Deaths Over Time"),
        ("avg_death_rate_trend.png", "Average Death Rate Over Time"),
        ("state_year_rate_heatmap.png", "Heatmap: Death Rate by State and Year"),
        ("poverty_vs_deathrate.png", "Poverty vs Death Rate"),
        ("unemp_vs_deathrate.png", "Unemployment vs Death Rate"),
        ("income_vs_deathrate.png", "Median Income vs Death Rate"),
        ("naloxone_vs_deathrate.png", "Naloxone Access vs Death Rate"),
        ("pdmp_vs_deathrate.png", "PDMP vs Death Rate"),
        ("medicaid_vs_deathrate.png", "Medicaid Expansion vs Death Rate"),
        ("feature_correlation.png", "Correlation Matrix of All Features"),
    ]

    for file, caption in eda_images:
        path = os.path.join(OUT_DIR, file)
        if os.path.exists(path):
            st.image(path, caption=caption, use_column_width=True)
            st.markdown("---")
        else:
            st.info(f"Image not found: {file}")

# ---------- 3) ML Forecast ----------
elif section == "ðŸ¤– Machine Learning Forecast":

    st.subheader("ðŸ¤– Machine Learning Prediction Results (XGBoost â€“ Panel Lag Model)")

    # ----------------------------
    # 1. Load & preprocess data
    # ----------------------------
    df = pd.read_csv("datasets/merged_data_final.csv")

    # Basic cleaning
    df = df[df["population"] > 0].copy()

    # Derive mortality rate  â†â­ å¿…é¡»åœ¨ lag1_rate ä¹‹å‰
    df["death_rate_per_100k"] = df["deaths"] / df["population"] * 1e5

    # Scale socioeconomic variables
    for col in ["poverty_population", "median_household_income", "unemployment_rate"]:
        df[f"{col}_scaled"] = (df[col] - df[col].mean()) / df[col].std()

    # State fixed effect dummies
    X_state = pd.get_dummies(df["state"], prefix="state", drop_first=False)

    # Sort and generate lag1_rate  â†â­ ä½¿ç”¨ä¸Šé¢é¢„å¤„ç†å¥½çš„ df
    df = df.sort_values(["state", "year"])
    df["lag1_rate"] = df.groupby("state", observed=True)["death_rate_per_100k"].shift(1)

    # ----------------------------
    # 2. Button to run model
    # ----------------------------
    if st.button("Run Full XGBoost Model ðŸš€"):

        with st.spinner("Training panel model with early stopping..."):

            # Temporal split (train â‰¤2018; test >2018)
            train_all = df[df["year"] <= 2018].dropna(subset=["lag1_rate"]).copy()
            test = df[df["year"] > 2018].dropna(subset=["lag1_rate"]).copy()

            trn = train_all[train_all["year"] <= 2017]
            val = train_all[train_all["year"] == 2018]

            # Design Matrix
            def design_matrix(frame, state_FE):
                cols = [
                    "pdmp_implemented", "naloxone_access", "medicaid_expansion",
                    "lag1_rate",
                    "poverty_population_scaled", "median_household_income_scaled",
                    "unemployment_rate_scaled",
                ]
                X = frame[cols].copy()
                return pd.concat([X, state_FE.reindex(frame.index)], axis=1)

            X_trn = design_matrix(trn, X_state)
            X_val = design_matrix(val, X_state)
            X_test = design_matrix(test, X_state)

            y_trn = trn["death_rate_per_100k"]
            y_val = val["death_rate_per_100k"]
            y_test = test["death_rate_per_100k"]

            # XGBoost params
            params = {
                "objective": "reg:squarederror",
                "eta": 0.05,
                "max_depth": 3,
                "min_child_weight": 3,
                "lambda": 1.0,
                "subsample": 0.9,
                "colsample_bytree": 0.8,
                "seed": 42,
                "eval_metric": "rmse",
            }

            # Convert to DMatrix
            dtrn = xgb.DMatrix(X_trn.values, y_trn.values)
            dval = xgb.DMatrix(X_val.values, y_val.values)
            dte = xgb.DMatrix(X_test.values)

            # Train
            bst = xgb.train(
                params,
                dtrn,
                num_boost_round=2000,
                evals=[(dval, "val")],
                early_stopping_rounds=50,
                verbose_eval=False
            )

            # Predict
            if bst.best_iteration is not None:
                y_pred = bst.predict(dte, iteration_range=(0, bst.best_iteration + 1))
            else:
                y_pred = bst.predict(dte)

            # Metrics
            rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))
            r2 = float(r2_score(y_test, y_pred))

        # Display Metrics
        c1, c2 = st.columns(2)
        c1.metric("XGBoost RÂ² (2019â€“2020)", f"{r2:.3f}")
        c2.metric("RMSE (per 100k)", f"{rmse:.2f}")

        # Predicted vs Actual Plot
        fig, ax = plt.subplots(figsize=(6, 5))
        ax.scatter(y_test, y_pred, alpha=0.7)
        ax.plot([y_test.min(), y_test.max()],
                [y_test.min(), y_test.max()],
                linestyle="--", color="gray")
        ax.set_xlabel("Actual")
        ax.set_ylabel("Predicted")
        ax.set_title(f"Predicted vs Actual (RÂ²={r2:.3f}, RMSE={rmse:.2f})")
        st.pyplot(fig)




# elif section == "ðŸ¤– Machine Learning Forecast":
#     st.subheader("ðŸ¤– Machine Learning Prediction Results (XGBoost)")

#     c1, c2 = st.columns(2)
#     c1.metric("XGBoost RÂ² (2019â€“2020)", "0.756")
#     c2.metric("XGBoost RMSE (per 100k)", "5.55")  
#     st.caption("Evaluated on held-out years 2019â€“2020 at the stateâ€“year level.")

#     for f, cap in [
#         ("png.png", "Predicted vs Actual Death Rate (2019â€“2020)"),
#         ("predicted_vs_actual_2019.png", "2019 Prediction"),
#         ("predicted_vs_actual_2020.png", "2020 Prediction"),
#         ("feature_importance.png", "Feature Importance (XGBoost)"),
#     ]:
#         p = os.path.join(OUT_DIR, f)
#         if os.path.exists(p):
#             st.image(p, caption=cap, use_column_width=True)
#         else:
#             st.info(f"Image not found: {f}")

# # ---------- 4) Policy Regression Results ----------
# elif section == "ðŸ“œ Policy Regression Results":
#     st.subheader("ðŸ“œ Policy Regression")

#     # --- Helper: load mixed effects summary as table for dynamic plot ---
#     @st.cache_data
#     def load_coef_table():
#         """Load mixed effects summary CSV and normalize headers to [variable, coef, pvalue]."""
#         path = os.path.join(DATA_DIR, "mixed_effects_summary.csv")
#         tbl = pd.read_csv(path)
#         tbl.columns = [c.strip().lower().replace(" ", "_") for c in tbl.columns]

#         def pick(cols, cands):
#             for c in cands:
#                 if c in cols:
#                     return c
#             return None

#         var_col = pick(tbl.columns, ["variable", "term", "param"])
#         coef_col = pick(tbl.columns, ["coef", "coefficient", "estimate"])
#         p_col   = pick(tbl.columns, ["pvalue", "p_value", "p", "pr", "pr_>|z|", "pr_>|t|"])
#         if not (var_col and coef_col and p_col):
#             raise ValueError("mixed_effects_summary.csv must contain variable/coef/pvalue columns.")

#         tbl = tbl[[var_col, coef_col, p_col]].rename(
#             columns={var_col: "variable", coef_col: "coef", p_col: "pvalue"}
#         )
#         tbl["variable"] = tbl["variable"].astype(str).str.strip()
#         tbl["coef"] = pd.to_numeric(tbl["coef"], errors="coerce")
#         tbl["pvalue"] = pd.to_numeric(tbl["pvalue"], errors="coerce")
#         tbl = tbl.dropna(subset=["coef", "pvalue"])
#         # Drop intercept to keep policy/economic terms only
#         tbl = tbl[~tbl["variable"].str.lower().isin(["intercept", "(intercept)"])]
#         return tbl

#     def pstars(p):
#         """Return significance stars based on p-value thresholds."""
#         if p < 0.001:
#             return "***"
#         elif p < 0.01:
#             return "**"
#         elif p < 0.05:
#             return "*"
#         else:
#             return ""

#     def render_coef_plot():
#         """Render a horizontal coefficient bar plot (positive=blue, negative=red) and save a PNG."""
#         try:
#             coef_df = load_coef_table()
#         except Exception as e:
#             st.error(f"Failed to load coefficients: {e}")
#             return

#         coef_df = coef_df.sort_values("coef")
#         coef_df["stars"] = coef_df["pvalue"].apply(pstars)

#         fig = plt.figure(figsize=(9, 5.5))
#         y = range(len(coef_df))
#         colors = coef_df["coef"].apply(lambda x: "steelblue" if x > 0 else "tomato")
#         plt.barh(list(y), coef_df["coef"], color=colors)
#         for i, (c, s) in enumerate(zip(coef_df["coef"], coef_df["stars"])):
#             xtext = c + (0.05 if c >= 0 else -0.05)
#             ha = "left" if c >= 0 else "right"
#             plt.text(xtext, i, f"{c:.2f} {s}", va="center", ha=ha)
#         plt.yticks(list(y), coef_df["variable"])
#         plt.axvline(0, linestyle="--", linewidth=1, color="gray")
#         plt.xlabel("Coefficient")
#         plt.title("Mixed Effects Model â€“ Policy Coefficients")
#         plt.tight_layout()

#         st.pyplot(fig, use_container_width=True)

#         # Persist a PNG for README/report reuse
#         os.makedirs(OUT_DIR, exist_ok=True)
#         fig.savefig(os.path.join(OUT_DIR, "policy_coef_plot.png"), dpi=300)

#         # Allow users to download the tidy coefficient table
#         st.download_button(
#             label="Download coefficient table (CSV)",
#             data=coef_df.to_csv(index=False).encode("utf-8"),
#             file_name="mixed_effects_coefficients_clean.csv",
#             mime="text/csv"
#         )

#     # --- 1) Main, high-signal visuals first ---
#     st.markdown("### 1) Mixed Effects (State Random Effects) â€“ Coefficients")
#     st.caption("Effects are shown after accounting for unobserved state heterogeneity (random effects). Stars: * p<0.05, ** p<0.01, *** p<0.001.")
#     render_coef_plot()

#     st.markdown("---")
#     st.markdown("### 2) Saved Figure & Brief Notes")
#     saved_img = os.path.join(OUT_DIR, "policy_coef_plot.png")
#     if os.path.exists(saved_img):
#         st.image(saved_img, caption="Saved figure: Policy effects on overdose death rate", use_column_width=True)
#     else:
#         st.info("Saved figure not found yet. Generate it via the dynamic plot above.")

#     # Short methodological note to frame expectations
#     st.info(
#         "Methodological note: Low RÂ² is common in public-health panels with high cross-state variance and unobserved shocks. "
#         "Our goal here is interpretability of policy associations (sign/direction and significance) under state heterogeneity, "
#         "while predictive performance is addressed by ML models in the Forecast section."
#     )

#     # --- 3) Put the full Panel OLS summary LAST, inside an expander ---
#     st.markdown("---")
#     with st.expander("Full Panel OLS summary (placed here for transparency)", expanded=False):
#         txt_path = os.path.join(OUT_DIR, "policy_regression_summary.txt")
#         if os.path.exists(txt_path):
#             with open(txt_path, "r") as f:
#                 st.text(f.read())
#         else:
#             st.info("Summary file not found: policy_regression_summary.txt")
